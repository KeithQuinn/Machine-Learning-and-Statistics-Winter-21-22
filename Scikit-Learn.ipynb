{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning and Statistics, Winter 21/22 Assessment - scikit-learn\n",
    "***\n",
    "## Notebook objectives\n",
    "* Provide a clear and concise overview of the scikit-learn Python library\n",
    "* Provide demonstrations of three interesting scikit-learn algorithms. You may choose these yourself, based on what is covered in class or otherwise. Note that the demonstrations are at your discretion – you may choose to have an overall spread of examples across the library or pick a particular part that you find interesting.\n",
    "* Appropriate plots and other visualisations to enhance your notebook for viewers.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning and Statistics, Winter 21/22 Assessment - scikit-learn\n",
    "***\n",
    "## 1) scikit-learn Introduction\n",
    "***\n",
    "\n",
    "Within the Python programming package there's a machine learning library known as scikit-learn. The scikit-learn library is integrated with other Python packages including NumPy, SciPy, matplotlib and Pandas [1].\n",
    "\n",
    "Scikit-learn was initially developed as a Google summer of code project in 2007 by David Cournapeau, then further developed by Fabian Pedregosa, Gael Varoquaux, Alexandre Gramfort and Vincent Michel from the French Institute for Research in Computer Science and Automation. The first public release was in January 2010 [2]. Many industries from engineering to banking to social media depend heavily on machine learning as part of their day to day operations and one of the most common tools used in the application of machine learning is the scikit-learn Python package. \n",
    "\n",
    "There are many machine learning algorithms built into the scikit-learn library that can be used for many types of machine learning applications. In the following section of this notebook there's an overview of what machine learning followed by some worked examples. In these examples, algorithms from the scikit-learn package are used to train models on datasets, then analyse how the algorithms perform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Machine Learning\n",
    "***\n",
    "Within computer science there's a subfield known as Artificial Intelligence (AI) and within AI there's a subfield known as Machine Learning. In traditional computer science the programmer/developer writes the program line by line and provides the data for the program to run. In machine learning the programmer/developer gives the system the data and the output and trains the system to produce the program [3].\n",
    "<br>\n",
    "<br>\n",
    "<div>\n",
    "<img src=\"TraditionalML.PNG\" width=\"300\"/>\n",
    "</div>\n",
    "\n",
    "<center><b> Figure 1: Traditional Computer Science vs Machine Learning </b></center>\n",
    "<br>\n",
    "\n",
    "With Machine learning there are models/algorithms that are trained using data, just like a human is trained on past experiences. The machine uses these models/algorithms to find patterns and make predictions, these predictions are made automatically without human interaction.\n",
    "\n",
    "<br>\n",
    "<div>\n",
    "<img src=\"MachineLearning.JPG\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "<center><b> Figure 2: Human learning and traditional computer programming </b></center>\n",
    "<br>\n",
    "\n",
    "\n",
    "Machine Learning is becoming increasingly popular in recent times with the advancements in computer science and technology. However it's important to note that this ever evolving area of computer science is not a new phenomenon as it's been studied for decades. In 1959, Arthur Samuel, a pioneer in the field of machine learning (ML) defined it as the “field of study that gives computers the ability to learn without being explicitly programmed”[4].In machine learning, algorithms are used to analyse data and in doing do look for patterns. The different data types that are analysed include but not limited to:\n",
    "\n",
    "* Numbers \n",
    "* Words \n",
    "* Images \n",
    "* Clicks \n",
    "\n",
    "Through data analysis and statistics the machine learns, and based on past conditions it can make predictions about the future. Machine learning is so interesting and powerful because anything that can be digitally stored can be fed into a machine learning algorithm. Another interesting part of machine learning is how common it is, it's used on systems such as Netflix and YouTube to recommend what to watch, also on search engines such as Google and Social media platforms such as Instagram and Facebook for advertising [5]. \n",
    "\n",
    "With all these systems the machine is collecting data around film genres that interest you, the music you listen to, the products you buy, what links you click, what posts you like or dislike, based on this past behaviour the machine can predict with confidence about what movie you'd like to watch next, the song you'd like to listen to next, where you'll spend your money and where you won't spend your money[5]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Supervised and Unsupervised Learning\n",
    "***\n",
    "Machine learning can be sub divided into two areas; machine learning through supervised learning and machine learning through unsupervised learning. The key difference between the two is that the data used in supervised learning is labeled and unlabeled  for unsupervised learning [6]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1) Supervised learning\n",
    "Labeled data is data that has the answer that the machine learning model has to predict [6]. From Figure 1 it can be seen that labelled data was used to train the machine, the data was labelled as \"cats\" based on the algorithm the machine was able to predict correctly when presented with 4 animals, two of which were cats. The following sections will discuss in more detail supervised and unsupervised learning.\n",
    "\n",
    "<div>\n",
    "<img src=\"Supervised_machine_learning.png\" width=\"700\"/>\n",
    "</div>\n",
    "\n",
    "<center><b> Figure 3 Labelled data for supervised learning </b></center>\n",
    "\n",
    "\n",
    "\n",
    "#### 2.1.2) Unsupervised learning\n",
    "Unsupervised learning means that the data in unlabeled meaning that it's impossible to pridict the accuracy of the model. In unsupervised learning the model is given the unlabeled dataset and will try to learn some sort of structure or pattern from the data. Clustering Algorithms are commonly used in unsupervised learning. Take for example a dataset of peoples heights and weights for a given age are provided but the data isn't labeled male or female. The unsupervised clustering algorithm can start to cluster the data into groups potentially resulting in two distinct clusters which through inference it could be said that the groups are male and female [7].\n",
    "\n",
    "<div>\n",
    "<img src=\"Unsupervised.PNG\" width=\"600\"/>\n",
    "</div>\n",
    "\n",
    "<center><b> Figure 4 Unsupervised and supervised learning </b></center>\n",
    "\n",
    "\n",
    "What's interesting in Figure 4 is that the same dataset was used to demonstrate supervised an unsupervised. In the supervised with the labelled data the groups can be split into male and female for example but in the unsupervised the two groups are just separated into two clusters with no labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Machine Learning Algorithms in scikit-learn\n",
    "***\n",
    "From the Machine Learning and Statistics module assessment specification - \"Demonstrations of three interesting scikit-learn algorithms. You may choose these yourself, based on what is covered in class or otherwise. Note that the demonstrations are at your discretion – you may choose to have an overall spread of examples across the library or pick a particular part that you find interesting.\"\n",
    "\n",
    "The approach for this part of the notebook is to pick three interesting scikit-learn algorithms. A high level overview of each of the algoithms is provided in this section. In the following sections there are worked examples of each of the three algorithms. The algorithms selected for this notebook are:\n",
    "\n",
    "* LinearRegression()\n",
    "* RandomForestClassifier()\n",
    "* KNeighborsClassifier()\n",
    "\n",
    "### 3.1) Regression and Classification\n",
    "***\n",
    "This notebook looks at supervised learning only. It's important to note that there are two types of supervised machine learning algorithms presented in this notebook, they are:\n",
    "\n",
    "* Regression\n",
    "* Classification\n",
    "\n",
    "Regression predicts continuous value outputs while classification predicts discrete outputs. For instance, predicting the weight of someone based on their height is a regression problem whereas predicting someones gender is a classification problem [8].\n",
    "\n",
    "\n",
    "### 3.2) LinearRegression()\n",
    "***\n",
    "Within regression, linear regression is the most basic machine learning algorithm. The model will predict an output based on inputs and learning. In this notebook LinearRegression() is used in two cases:\n",
    "\n",
    "* predict if someone has diabetes.\n",
    "* predict the price of house prices in Boston.\n",
    "\n",
    "The diabetes dataset is a built in dataset and the Boston house prices dataset was sourced online (reference included below).\n",
    "\n",
    "### 3.3) RandomForestClassifier()\n",
    "***\n",
    "RandomForestClassifier() can be used for regression or for classification. A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is controlled with the max_samples parameter if bootstrap=True (default), otherwise the whole dataset is used to build each tree [9]. The RandomForestClassifier() is used in this notebook along with the iris data set. A model is built that can predict the Iris class based on a never before seen set of inputs. \n",
    "\n",
    "### 3.4) KNeighborsClassifier()\n",
    "***\n",
    "The k-nearest neighbors (KNN) algorithm is a simple, easy-to-implement supervised machine learning algorithm that can be used to solve both classification and regression problems. The KNN algorithm assumes that similar things exist in close proximity. In other words, similar things are near to each other [10]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import matplotlib.pyplot as plt # plotting library\n",
    "from sklearn import datasets # datasets built into scikit-learn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split # import train_test_split from scikit-learn library\n",
    "from sklearn import linear_model # importing linear_model from scikit-learn\n",
    "from sklearn.metrics import mean_squared_error, r2_score # importing some statistics packages from scikit-learn\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) scikit-learn Algorithm 1 - LinearRegression()\n",
    "***\n",
    "\n",
    "### 4.1) LinearRegression() - Diabetes dataset [11]\n",
    "***\n",
    "\n",
    "The diabetes data set consists of ten baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements were obtained for each of n = 442 diabetes patients, as well as the response of interest, a quantitative measure of disease progression one year after baseline. Full details of the dataset are provided after running the following code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset shape: (442, 10)\n",
      "\n",
      "Diabetes labels shape: (442,)\n",
      "\n",
      "Diabetes feature names: ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n",
      "\n",
      "\n",
      "|------------------------------------------- DataSet Description -------------------------------------------|\n",
      "\n",
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - age     age in years\n",
      "      - sex\n",
      "      - bmi     body mass index\n",
      "      - bp      average blood pressure\n",
      "      - s1      tc, T-Cells (a type of white blood cells)\n",
      "      - s2      ldl, low-density lipoproteins\n",
      "      - s3      hdl, high-density lipoproteins\n",
      "      - s4      tch, thyroid stimulating hormone\n",
      "      - s5      ltg, lamotrigine\n",
      "      - s6      glu, blood sugar level\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset from scikit-learn dataset library\n",
    "diabetes = datasets.load_diabetes() # loads the dataset\n",
    "print()\n",
    "print('Dataset shape:',diabetes.data.shape) # shape of the data\n",
    "print()\n",
    "print('Diabetes labels shape:',diabetes.target.shape) # shape of the target (y-variable)\n",
    "print()\n",
    "print('Diabetes feature names:',diabetes.feature_names) # feature names (x-variables)\n",
    "print()\n",
    "print()\n",
    "print('|------------------------------------------- DataSet Description -------------------------------------------|')\n",
    "print()\n",
    "print(diabetes.DESCR) # description of the dataset\n",
    "\n",
    "df = pd.DataFrame(data=diabetes.data, columns=diabetes.feature_names) # setting dataframe for the features (x-variables)\n",
    "df[\"target\"] = diabetes.target # setting dataframe for the labels (y-variables)\n",
    "\n",
    "X,Y = diabetes = datasets.load_diabetes(return_X_y=True) # setting X and Y to features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6  target  \n",
       "0 -0.002592  0.019908 -0.017646   151.0  \n",
       "1 -0.039493 -0.068330 -0.092204    75.0  \n",
       "2 -0.002592  0.002864 -0.025930   141.0  \n",
       "3  0.034309  0.022692 -0.009362   206.0  \n",
       "4 -0.002592 -0.031991 -0.046641   135.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # check that the correct dataset is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((442, 10), (442,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape # 10 features and 442 rows, and 1 target with 442 rows "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1) Splitting the data\n",
    "***\n",
    "With the data loaded and description provided above the next step is to start setting up the data for the model. The first step is to import the train_test_split function from the scikit-learn library. This function is very useful as it enables functionality to split the data into training and testing groups. In the example below the test size is set to 0.2 meaning that 20% of the data is held for testing the model, the other 80% is usedto train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2) # split the data into 80% train, 20% test for both the features and the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((353, 10), (353,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape # original dataset was 442,10, 80% of this is 353,10 for features and 353,1 for target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((89, 10), (89,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, Y_test.shape # original dataset was 442,10, 20% of this is 89,10 for features and 89, 1 for target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2) Linear Regression Model\n",
    "***\n",
    "In this section the Linear Regression Model is built. This starts by importing the linear_model from the scikit-learn library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.LinearRegression() # define the model as LinearRegression() from linear_model\n",
    "model.fit(X_train, Y_train) # train the model using the data, X_train being the features, Y_train being the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3) Predict the output\n",
    "In this section the model is used to predict using the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = np.round(model.predict(X_test),2) # predict Y values using the X_test inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.4) Model Performance\n",
    "***\n",
    "In this section the performance of the model is shown, included are the coefficients for each feature, the intercept, the mean squared error and the coefficient of determinition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [ -15.98582684 -228.35945185  534.56970659  341.80996556 -949.98020762\n",
      "  575.65993177  162.00839162  174.40245046  794.22770503  115.02222489]\n",
      "Intercept: 155.49706428731804\n",
      "Mean squared error (MSE): 3464.252\n",
      "Coefficient of determination (R^2): 0.297\n"
     ]
    }
   ],
   "source": [
    "print('Coefficients:', model.coef_) # coefficients of the linear regression model for each feature\n",
    "print('Intercept:', model.intercept_) # the model Y interept\n",
    "print('Mean squared error (MSE): %.3f' % mean_squared_error(Y_test, Y_pred)) # mean squared error\n",
    "print('Coefficient of determination (R^2): %.3f' % r2_score(Y_test, Y_pred)) # coefficient of determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.74 %\n"
     ]
    }
   ],
   "source": [
    "print(f'{(round(model.score(X_test, Y_test)*100,2))} %') # model score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\quinnk4\\Anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1afb2c25d60>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(Y_test, Y_pred, alpha = 0.5) # scatterplot showing spread of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2) LinearRegression() - Boston Housing dataset [11] \n",
    "***\n",
    "[8]\n",
    "The diabetes data set consists of Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target. Number of Instances: 506. Full details of the Boston Housing dataset  are provided after running the following code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Boston Housing shape: (506, 13)\n",
      "\n",
      "Boston Housing shape: (506,)\n",
      "\n",
      "Boston Housing names: ['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n",
      "\n",
      "\n",
      "|------------------------------------------- DataSet Description -------------------------------------------|\n",
      "\n",
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "boston = datasets.load_boston() # Load dataset from scikit-learn dataset library\n",
    "print()\n",
    "print('Boston Housing shape:',boston.data.shape) # shape of the data\n",
    "print()\n",
    "print('Boston Housing shape:',boston.target.shape) # shape of the target (y-variable)\n",
    "print()\n",
    "print('Boston Housing names:',boston.feature_names)  # feature names (x-variables)\n",
    "print()\n",
    "print()\n",
    "print('|------------------------------------------- DataSet Description -------------------------------------------|')\n",
    "print()\n",
    "print(boston.DESCR) # description of the dataset\n",
    "\n",
    "df = pd.DataFrame(data=boston.data, columns=boston.feature_names)\n",
    "df[\"medv\"] = boston.target # setting dataframe for the labels (y-variables)\n",
    "\n",
    "X,Y = boston = datasets.load_boston(return_X_y=True) # setting X and Y to features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  medv  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # 13 features and 1 target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1) Splitting the data\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['medv'], axis=1) # x variables\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    24.0\n",
       "1    21.6\n",
       "2    34.7\n",
       "3    33.4\n",
       "4    36.2\n",
       "Name: medv, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = df['medv'] # y variable\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2) Linear Regression Model\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2) # split the data into 80% train, 20% test for both the features and the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404, 13), (404,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape # original dataset was 506,13, 80% of this is 404,13 for features and 404, 1 for target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((102, 13), (102,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, Y_test.shape # original dataset was 506,13, 20% of this is 102,13 for features and 102,1 for target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.LinearRegression() # define the model as LinearRegression() from linear_model\n",
    "model.fit(X_train, Y_train)# train the model using the data, X_train being the features, Y_train being the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3) Predict the output\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = np.round(model.predict(X_test),2) # predict Y values using the X_test inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.4) Model Performance\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-7.87070251e-02  4.07686075e-02  1.65122499e-02  6.80034434e-01\n",
      " -1.50590837e+01  4.66497795e+00 -9.78651681e-03 -1.42441254e+00\n",
      "  2.56829959e-01 -1.32886818e-02 -8.54409588e-01  1.09993028e-02\n",
      " -4.14842965e-01]\n",
      "Intercept: 27.209270144448297\n",
      "Mean squared error (MSE): 31.958\n",
      "Coefficient of determination (R^2): 0.687\n"
     ]
    }
   ],
   "source": [
    "print('Coefficients:', model.coef_) # coefficients of the linear regression model for each feature\n",
    "print('Intercept:', model.intercept_) # the model Y interept\n",
    "print('Mean squared error (MSE): %.3f' % mean_squared_error(Y_test, Y_pred)) # mean squared error\n",
    "print('Coefficient of determination (R^2): %.3f' % r2_score(Y_test, Y_pred)) # coefficient of determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.74 %\n"
     ]
    }
   ],
   "source": [
    "print(f'{(round(model.score(X_test, Y_test)*100,2))} %') # model score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\quinnk4\\Anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1afb34199d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " sns.scatterplot(Y_pred, Y_test) # scatterplot showing spread of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) scikit-learn Algorithm 2 - RandomForestClassifier()\n",
    "***\n",
    "### 5.1) RandomForestClassifier() - Iris dataset [12]\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.1) Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier # import RandomForestClassifier from scikit learn.\n",
    "from sklearn.datasets import make_classification # import make_classification from scikit learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2) Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris() # loading the iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.3) View the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print(iris.feature_names) # print the feature names\n",
    "print(iris.target) # print iris targets\n",
    "print(iris.target_names) # print iris target names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(iris.DESCR) # full description of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.4) Setting the variables and displaying the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data # X id defined as the iris features.\n",
    "Y = iris.target # Y is defined as the iris labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape # shape of X, 150 rows with 4 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape # shape of Y, 150 rows with 1 set of labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.5) Training the model using all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier() # setting RandomForestClassifier() equal to clf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, Y) # training the model using all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11012527 0.02561829 0.4439083  0.42034814]\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "print(clf.feature_importances_)\n",
    "print(iris.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.5) Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.1, 3.5, 1.4, 0.2])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0] # value of X at position 0 to be used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict([[1, 5.5, 4, 5.2]])) # make prediction using the inputs provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict_proba(X[[0]])) # the probability of the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(iris.data, iris.target_names[iris.target]) # to get the names of the targets from the numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.6) Training the model using train_test_split\n",
    "The previous model used the full data set to train the model, next section looks at train_test_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2) # train the model using 80% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 4), (120,))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape # 80% of the original dataset 150 is 120."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30, 4), (30,))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, Y_test.shape # 20% of the original dataset 150 is 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, Y_train) # training the model using 80% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict([[5.1, 3.5, 1.4, 0.2]])) # make prediction using the inputs provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict_proba(X[[0]])) # the probability of the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 1 0 0 1 0 1 1 0 2 2 1 0 0 2 1 0 1 2 2 1 1 2 2 1 2 0]\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict(X_test)) # make predictions on the 20% of the data left out from training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 1 0 0 1 0 1 1 0 2 2 1 0 0 2 1 0 1 2 1 1 1 2 2 1 2 0]\n"
     ]
    }
   ],
   "source": [
    "print(Y_test) # the 20% of the labeled data, will be used to make comparisons with the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.7) Analysing the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(X_test, Y_test)) # compares the predicted with the actual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) scikit-learn Algorithm 3 - KNeighborsClassifier()\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1) Import libraries\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, neighbors # import preprocessing and neighbors from scikit-learn.\n",
    "from sklearn.model_selection import cross_validate # import cross_validate from scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2) Read in Dataset\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>clump_thickness</th>\n",
       "      <th>unif_cell_size</th>\n",
       "      <th>unif_cell_shape</th>\n",
       "      <th>marg_adhesion</th>\n",
       "      <th>single_epith_cell_size</th>\n",
       "      <th>bare_nuclei</th>\n",
       "      <th>bland_chrom</th>\n",
       "      <th>norm_nucleoli</th>\n",
       "      <th>mitoses</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  clump_thickness  unif_cell_size  unif_cell_shape  marg_adhesion  \\\n",
       "0  1000025                5               1                1              1   \n",
       "1  1002945                5               4                4              5   \n",
       "2  1015425                3               1                1              1   \n",
       "3  1016277                6               8                8              1   \n",
       "4  1017023                4               1                1              3   \n",
       "\n",
       "   single_epith_cell_size bare_nuclei  bland_chrom  norm_nucleoli  mitoses  \\\n",
       "0                       2           1            3              1        1   \n",
       "1                       7          10            3              2        1   \n",
       "2                       2           2            3              1        1   \n",
       "3                       3           4            3              7        1   \n",
       "4                       2           1            3              1        1   \n",
       "\n",
       "   class  \n",
       "0      2  \n",
       "1      2  \n",
       "2      2  \n",
       "3      2  \n",
       "4      2  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('breast-cancer-wisconsin.data')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3) Tidy up Dataset\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('?', -99999, inplace=True) # replace the missing data with -99999, algorithm recognises this as an outlier and will treat it as such.\n",
    "df.drop(['id'], 1, inplace=True) # drop id column to avoid unnecessary noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clump_thickness</th>\n",
       "      <th>unif_cell_size</th>\n",
       "      <th>unif_cell_shape</th>\n",
       "      <th>marg_adhesion</th>\n",
       "      <th>single_epith_cell_size</th>\n",
       "      <th>bare_nuclei</th>\n",
       "      <th>bland_chrom</th>\n",
       "      <th>norm_nucleoli</th>\n",
       "      <th>mitoses</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     clump_thickness  unif_cell_size  unif_cell_shape  marg_adhesion  \\\n",
       "694                3               1                1              1   \n",
       "695                2               1                1              1   \n",
       "696                5              10               10              3   \n",
       "697                4               8                6              4   \n",
       "698                4               8                8              5   \n",
       "\n",
       "     single_epith_cell_size bare_nuclei  bland_chrom  norm_nucleoli  mitoses  \\\n",
       "694                       3           2            1              1        1   \n",
       "695                       2           1            1              1        1   \n",
       "696                       7           3            8             10        2   \n",
       "697                       3           4           10              6        1   \n",
       "698                       4           5           10              4        1   \n",
       "\n",
       "     class  \n",
       "694      2  \n",
       "695      2  \n",
       "696      4  \n",
       "697      4  \n",
       "698      4  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail() # shows cleaned data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4) Setting the variables\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df.drop(['class'], 1)) # setting the features as X\n",
    "y = np.array(df['class']) # setting class as the labeled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5) Splitting the data\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) # splitting the data 80% training, 20% testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6) Training the model\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = neighbors.KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7) Checking model accuracy\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9785714285714285\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.8) Make a prediction\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_measures = np.array([4,2,1,1,1,2,3,2,1]) # making up an input to feed into the model\n",
    "example_measures = example_measures.reshape(1, -1) # reshaping the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "prediction = clf.predict(example_measures) # making a prediction\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Machine Learning for Tube Classification\n",
    "***\n",
    "Taking an example from my workplace where there are 4 tubes processed. The tubes have two variables UGBL and OD and there are 4 classes numbered 1 to 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1) Reading in the dataset\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UGBL</th>\n",
       "      <th>OD</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.27</td>\n",
       "      <td>1.5766</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.28</td>\n",
       "      <td>1.5790</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.21</td>\n",
       "      <td>1.5782</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.29</td>\n",
       "      <td>1.5782</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.30</td>\n",
       "      <td>1.5776</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>26.84</td>\n",
       "      <td>1.8018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>26.80</td>\n",
       "      <td>1.8032</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>26.84</td>\n",
       "      <td>1.8046</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>26.72</td>\n",
       "      <td>1.8018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>26.75</td>\n",
       "      <td>1.8050</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      UGBL      OD  Class\n",
       "0    19.27  1.5766      1\n",
       "1    19.28  1.5790      1\n",
       "2    19.21  1.5782      1\n",
       "3    19.29  1.5782      1\n",
       "4    19.30  1.5776      1\n",
       "..     ...     ...    ...\n",
       "195  26.84  1.8018      4\n",
       "196  26.80  1.8032      4\n",
       "197  26.84  1.8046      4\n",
       "198  26.72  1.8018      4\n",
       "199  26.75  1.8050      4\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tube_df = pd.read_csv(\"TubeData2.csv\") # reading in the file\n",
    "tube_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\quinnk4\\Anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1afb3f21580>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style(\"white\")\n",
    "sns.scatterplot(tube_df['OD'], tube_df['UGBL'], hue=tube_df['Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2) Tidying up the data and setting the variables\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UGBL</th>\n",
       "      <th>OD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.27</td>\n",
       "      <td>1.5766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.28</td>\n",
       "      <td>1.5790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.21</td>\n",
       "      <td>1.5782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.29</td>\n",
       "      <td>1.5782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.30</td>\n",
       "      <td>1.5776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    UGBL      OD\n",
       "0  19.27  1.5766\n",
       "1  19.28  1.5790\n",
       "2  19.21  1.5782\n",
       "3  19.29  1.5782\n",
       "4  19.30  1.5776"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tube_df.drop(['Class'], axis=1) # x variables\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = tube_df['Class'] # y variable\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3) Splitting the data into train and test\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20) # spltting the data into 80/20 train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((160, 2), (160,))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape # 80% of the original dataset 200 is 160."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40, 2), (40,))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, Y_test.shape # 20% of the original dataset 200 is 40."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4) Training the model\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tube_clf = RandomForestClassifier() # setting RandomForestClassifier() equal to tube_clf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tube_clf.fit(X_train, Y_train) # training the model using 80% of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5) Feature Importance\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60777944 0.39222056]\n"
     ]
    }
   ],
   "source": [
    "print(tube_clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6) Making Predictions\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UGBL</th>\n",
       "      <th>OD</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.27</td>\n",
       "      <td>1.5766</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.28</td>\n",
       "      <td>1.5790</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.21</td>\n",
       "      <td>1.5782</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.29</td>\n",
       "      <td>1.5782</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.30</td>\n",
       "      <td>1.5776</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>26.84</td>\n",
       "      <td>1.8018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>26.80</td>\n",
       "      <td>1.8032</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>26.84</td>\n",
       "      <td>1.8046</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>26.72</td>\n",
       "      <td>1.8018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>26.75</td>\n",
       "      <td>1.8050</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      UGBL      OD  Class\n",
       "0    19.27  1.5766      1\n",
       "1    19.28  1.5790      1\n",
       "2    19.21  1.5782      1\n",
       "3    19.29  1.5782      1\n",
       "4    19.30  1.5776      1\n",
       "..     ...     ...    ...\n",
       "195  26.84  1.8018      4\n",
       "196  26.80  1.8032      4\n",
       "197  26.84  1.8046      4\n",
       "198  26.72  1.8018      4\n",
       "199  26.75  1.8050      4\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tube_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[4]\n",
      "[2]\n",
      "[3]\n"
     ]
    }
   ],
   "source": [
    "print(tube_clf.predict([[19.27, 1.57]])) # make prediction using the inputs provided.\n",
    "print(tube_clf.predict([[26.84, 1.80]])) # make prediction using the inputs provided.\n",
    "print(tube_clf.predict([[28.4, 1.576]])) # make prediction using the inputs provided.\n",
    "print(tube_clf.predict([[19.27, 1.80]])) # make prediction using the inputs provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 4 4 2 3 1 1 1 3 2 1 2 2 4 3 3 3 3 1 2 4 3 2 3 4 3 1 4 1 4 1 2 2 3 2 4 4\n",
      " 2 2 3]\n"
     ]
    }
   ],
   "source": [
    "print(tube_clf.predict(X_test)) # make predictions on the 20% of the data left out from training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176    4\n",
       "175    4\n",
       "58     2\n",
       "87     2\n",
       "112    3\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.tail() # the 20% of the labeled data, will be used to make comparisons with the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.7) Model score\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(tube_clf.score(X_test, Y_test)) # compares the predicted with the actual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Summary\n",
    "***\n",
    "This notebook starts out with an overview of the scikit-learn Python library; what it is, where it came from and where and why it is used. The next section details machine learning and it's relationship to artificial intelligence and computer science. Where machine learning is used, how common it has become and how it's used on a daily basis across everything from streaming platforms to banks and social media is discussed. \n",
    "\n",
    "Technical aspects of machine learning such as the supervised and unsupervised approaches are discussed before looking at machine learning algorithms in scikit-learn. Three scikit-learn algorithms are then discussed and demonstrated:\n",
    "\n",
    "* LinearRegression()\n",
    "* RandomForestClassifier()\n",
    "* KNeighborsClassifier()\n",
    "\n",
    "With the introduction complete and some background on machine learning along with the selection of three scikit-learn algorithm the next section of the notebook provides some practical examples of each of the three algorithms. \n",
    "\n",
    "* For the LinearRegression() algorithm the diabetes dataset and the Boston Housing dataset are used for demonstration. \n",
    "* For the RandomForestClassifier() algorithm the Iris dataset along with a dataset obtained from my workplace are used for demonstration.\n",
    "* For the KNeighborsClassifier() algorithm the breast-cancer-wisconsin dataset was used for demonstration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Conclusion\n",
    "***\n",
    "This assessment was really interesting, initially starting off it seemed really difficult. The concept of training a machine seemed like something only highly qualified and skilled programmers could do. Although initially it took some time to get an understanding of machine learning concepts such as supervised and unsupervised learning, it was an enjoyable learning experience. \n",
    "\n",
    "The biggest eye opening part of completing this assessment was the power of the scikit-learn library in Python and how intuitive and straight forward it is to use. Given a dataset and a couple of lines of code it's possible to train a machine to make predictions based on inputs it never seen before. I can only imagine the work and effort that went into creating and maintaining this library.\n",
    "\n",
    "The coolest thing about building the knowledge around machine learning and the scikit-learn package was that I was able to take some data from my workplace and train the machine to make a prediction. My plan is to present this to my colleagues in work and to show them the power of the scikit-learn package within Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) References\n",
    "***\n",
    "[1] scikit-learn; Machine Learning in Python; https://scikit-learn.org/stable/\n",
    "\n",
    "[2] tutorialspoint; Scikit Learn - Introduction; https://www.tutorialspoint.com/scikit_learn/scikit_learn_introduction.htm\n",
    "\n",
    "[3] Snehit Vaddi; Most used Scikit-Learn Algorithms;  https://medium.com/analytics-vidhya/most-used-scikit-learn-algorithms-part-1-snehit-vaddi-7ec0c98e4edd\n",
    "\n",
    "[4] Udemy; SciKit-Learn in Python for Machine Learning Engineers; https://www.udemy.com/course/scikit-learn-in-python-for-machine-learning-engineers/\n",
    "\n",
    "[5] Technology Review; What is machine learning?; https://www.technologyreview.com/2018/11/17/103781/what-is-machine-learning-we-drew-you-another-flowchart/\n",
    "\n",
    "[6] cloudfactory; The Ultimate Guide to Data Labeling for Machine Learning; https://www.cloudfactory.com/data-labeling-guide#:~:text=What%20is%20labeled%20data%3F,machine%20learning%20model%20to%20predict.\n",
    "\n",
    "[7] IBM; Supervised vs. Unsupervised Learning: What’s the Difference?; https://www.ibm.com/cloud/blog/supervised-vs-unsupervised-learning\n",
    "\n",
    "[8] Jason Brownlee; Difference Between Classification and Regression in Machine Learning; https://machinelearningmastery.com/classification-versus-regression-in-machine-learning/\n",
    "\n",
    "[9] scikit-learn; sklearn.ensemble.RandomForestClassifier; https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "[10] datacamp; KNN Classification using Scikit-learn; https://www.datacamp.com/community/tutorials/k-nearest-neighbor-classification-scikit-learn\n",
    "\n",
    "[11] Data Professor; Machine Learning in Python: Building a Linear Regression Model; https://www.youtube.com/watch?v=R15LjD8aCzc\n",
    "\n",
    "[12] Data Professor; Machine Learning in Python: Building a Classification Model; https://www.youtube.com/watch?v=XmSlFPDjKdc\n",
    "\n",
    "[13] sentdex; K Nearest Neighbors Application - Practical Machine Learning Tutorial with Python p.14; https://www.youtube.com/watch?v=1i0zu9jHN6U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
